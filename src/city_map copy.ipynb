{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52686129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import polyline\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89776c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cars_on_graph(G, cars):\n",
    "    # Plot the road network first\n",
    "    fig, ax = ox.plot_graph(G, node_color='black', node_size=5, edge_linewidth=0.5, bgcolor ='white', show=False, close=False,)\n",
    "\n",
    "    # Extract coordinates separately for batch plotting\n",
    "    src_lats = [car['src_coords'][0] for car in cars]\n",
    "    src_lons = [car['src_coords'][1] for car in cars]\n",
    "    dst_lats = [car['dst_coords'][0] for car in cars]\n",
    "    dst_lons = [car['dst_coords'][1] for car in cars]\n",
    "\n",
    "    # Plot origins (green circles)\n",
    "    ax.scatter(src_lons, src_lats, c='green', marker='o', s=30, label='Origin', zorder=3)\n",
    "\n",
    "    # Plot destinations (red Xs)\n",
    "    ax.scatter(dst_lons, dst_lats, c='red', marker='x', s=30, label='Destination', zorder=3)\n",
    "\n",
    "    # Optional: connect each OD pair with a line\n",
    "    for car in cars:\n",
    "        ax.plot(\n",
    "            [car['src_coords'][1], car['dst_coords'][1]],\n",
    "            [car['src_coords'][0], car['dst_coords'][0]],\n",
    "            color='blue', linewidth=1, alpha=0.5\n",
    "        )\n",
    "\n",
    "    # Add legend and title\n",
    "    ax.legend()\n",
    "    plt.title(\"Car Origins (green) and Destinations (red)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cars_on_graph(G, CARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aacdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_route_overlap_congestion(car_routes, precision=5):\n",
    "    \"\"\"\n",
    "    Calculates congestion score based on overlapping route points,\n",
    "    ensuring each car contributes only once per point.\n",
    "\n",
    "    Returns:\n",
    "        congestion_scores: dict {(car_id, route_index): congestion_score}\n",
    "        point_freq: dict {point: number of unique cars using the point}\n",
    "    \"\"\"\n",
    "    point_to_cars = defaultdict(set)\n",
    "\n",
    "    # Step 1: For each car, register unique points it visits (across all its routes)\n",
    "    for car in car_routes:\n",
    "        car_id = car['car_id']\n",
    "        car_points = set()\n",
    "        for route in car.get('routes', []):\n",
    "            for lat, lon in route['geometry']:\n",
    "                key = (round(lat, precision), round(lon, precision))\n",
    "                car_points.add(key)\n",
    "        for key in car_points:\n",
    "            point_to_cars[key].add(car_id)\n",
    "\n",
    "    # Step 2: Build a frequency map of unique cars per point\n",
    "    point_freq = {key: len(cars) for key, cars in point_to_cars.items()}\n",
    "\n",
    "    # Step 3: For each route, compute average congestion\n",
    "    congestion_scores = {}\n",
    "    for car in car_routes:\n",
    "        car_id = car['car_id']\n",
    "        for idx, route in enumerate(car.get('routes', [])):\n",
    "            total = 0\n",
    "            for lat, lon in route['geometry']:\n",
    "                key = (round(lat, precision), round(lon, precision))\n",
    "                total += point_freq.get(key, 0)\n",
    "            avg_congestion = total / max(len(route['geometry']), 1)\n",
    "            congestion_scores[(car_id, idx)] = avg_congestion\n",
    "\n",
    "    return congestion_scores, point_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4768be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONGESTION_SCORES, POINT_FREQ = compute_route_overlap_congestion(CAR_ROUTES)\n",
    "print(CONGESTION_SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bb671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import Map, PolyLine, Marker\n",
    "from branca.colormap import linear\n",
    "\n",
    "def visualize_routes_by_overlap_congestion(car_routes, congestion_scores):\n",
    "    if not car_routes:\n",
    "        print(\"No routes to display.\")\n",
    "        return None\n",
    "\n",
    "    # Center map on the first available route\n",
    "    for car in car_routes:\n",
    "        if car.get(\"routes\"):\n",
    "            center = car[\"origin\"]\n",
    "            break\n",
    "    else:\n",
    "        print(\"⚠️ No cars have routes.\")\n",
    "        return None\n",
    "\n",
    "    fmap = folium.Map(location=center, zoom_start=13, tiles='cartodbpositron')\n",
    "\n",
    "    # Normalize congestion scores for colormap\n",
    "    all_scores = list(congestion_scores.values())\n",
    "    colormap = linear.YlOrRd_09.scale(min(all_scores), max(all_scores))\n",
    "    colormap.caption = \"Route Overlap-Based Congestion\"\n",
    "    fmap.add_child(colormap)\n",
    "\n",
    "    for car in car_routes:\n",
    "        car_id = car['car_id']\n",
    "        routes = car.get('routes', [])\n",
    "        if not routes:\n",
    "            continue\n",
    "\n",
    "        # Add start and end markers\n",
    "        #Marker(location=car['origin'], popup=f\"Car {car_id} Start\").add_to(fmap)\n",
    "        #Marker(location=car['destination'], popup=f\"Car {car_id} End\").add_to(fmap)\n",
    "\n",
    "        for idx, route in enumerate(routes):\n",
    "            poly = route['geometry']\n",
    "            dist_m = route.get('distance', 0)\n",
    "            time_sec = route.get('duration', 0)\n",
    "            score = congestion_scores.get((car_id, idx), 0)\n",
    "            color = colormap(score)\n",
    "\n",
    "            tooltip_text = (\n",
    "                f\"Car {car_id} - Route {idx}<br>\"\n",
    "                f\"Distance: {dist_m / 1000:.2f} km<br>\"\n",
    "                f\"Duration: {time_sec // 60:.1f} min<br>\"\n",
    "                f\"Congestion Score: {score:.2f}\"\n",
    "            )\n",
    "\n",
    "            PolyLine(\n",
    "                locations=poly,\n",
    "                color=color,\n",
    "                weight=4,\n",
    "                opacity=0.7,\n",
    "                tooltip=tooltip_text\n",
    "            ).add_to(fmap)\n",
    "\n",
    "    return fmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a224bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute congestion scores\n",
    "congestion_scores, _ = compute_route_overlap_congestion(CAR_ROUTES)\n",
    "\n",
    "# Step 2: Visualize map\n",
    "map_overlap = visualize_routes_by_overlap_congestion(CAR_ROUTES, congestion_scores)\n",
    "map_overlap.save(\"routes_by_overlap_congestion.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc97fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights_from_congestion_scores(congestion_scores):\n",
    "    \"\"\"\n",
    "    Computes adjusted weights w(i,j,k) by subtracting self-overlap from congestion scores.\n",
    "\n",
    "    Args:\n",
    "        congestion_scores: dict {(i, k): score}\n",
    "\n",
    "    Returns:\n",
    "        weights[i][j][k]: shared weight from congestion (ignoring self-use)\n",
    "    \"\"\"\n",
    "    weights = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    all_keys = congestion_scores.keys()\n",
    "    cars = sorted(set(i for i, _ in all_keys))\n",
    "    ks = sorted(set(k for _, k in all_keys))\n",
    "\n",
    "    for i, j in combinations(cars, 2):\n",
    "        for k in ks:\n",
    "            if (i, k) in congestion_scores and (j, k) in congestion_scores:\n",
    "                score_i = max(0, congestion_scores[(i, k)] - 1)\n",
    "                score_j = max(0, congestion_scores[(j, k)] - 1)\n",
    "                avg = (score_i + score_j) / 2\n",
    "                weights[i][j][k] = avg\n",
    "                weights[j][i][k] = avg\n",
    "            else:\n",
    "                weights[i][j][k] = 0\n",
    "                weights[j][i][k] = 0\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd69435",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = calculate_weights_from_congestion_scores(congestion_scores)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132002d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def normalize_point(p, precision=5):\n",
    "    \"\"\"Round a lat/lon point to the given decimal precision.\"\"\"\n",
    "    return (round(p[0], precision), round(p[1], precision))\n",
    "\n",
    "def normalize_segment(segment, precision=5):\n",
    "    a = normalize_point(segment[0], precision)\n",
    "    b = normalize_point(segment[1], precision)\n",
    "    return (a, b)  # direction matters now!\n",
    "\n",
    "\n",
    "def build_car_overlap_graph(car_routes, precision=5):\n",
    "    \"\"\"\n",
    "    car_routes: dict of car_id -> list of route alternatives (each route is a list of segments)\n",
    "    Each segment is a tuple: ((lat1, lon1), (lat2, lon2))\n",
    "    \"\"\"\n",
    "    segment_to_cars = defaultdict(set)\n",
    "\n",
    "    for car_id, routes in car_routes.items():\n",
    "        for route in routes:\n",
    "            for segment in route:\n",
    "                norm_seg = normalize_segment(segment, precision)\n",
    "                segment_to_cars[norm_seg].add(car_id)\n",
    "\n",
    "    # Initialize graph\n",
    "    G = nx.Graph()\n",
    "    overlap_counts = defaultdict(int)\n",
    "\n",
    "    for segment, cars in segment_to_cars.items():\n",
    "        for car1, car2 in combinations(cars, 2):\n",
    "            pair = tuple(sorted((car1, car2)))\n",
    "            overlap_counts[pair] += 1\n",
    "\n",
    "    for (car1, car2), weight in overlap_counts.items():\n",
    "        G.add_edge(car1, car2, weight=weight)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00829752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_cars(overlap_graph):\n",
    "    \"\"\"\n",
    "    Returns: list of sets of car_ids, each set is a cluster\n",
    "    \"\"\"\n",
    "    return list(nx.connected_components(overlap_graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75098a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_routes_to_segments(car_routes_raw):\n",
    "    def to_segments(points):\n",
    "        return [(points[i], points[i + 1]) for i in range(len(points) - 1)]\n",
    "\n",
    "    transformed = {}\n",
    "    for car in car_routes_raw:\n",
    "        car_id = car['car_id']\n",
    "        routes = [to_segments(route['geometry']) for route in car['routes']]\n",
    "        transformed[car_id] = routes\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4139ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use it like this:\n",
    "car_routes_segments = transform_routes_to_segments(CAR_ROUTES)\n",
    "print(car_routes_segments)\n",
    "OVERLAP_GRAPH = build_car_overlap_graph(car_routes_segments)\n",
    "print(OVERLAP_GRAPH)\n",
    "L_ = cluster_cars(OVERLAP_GRAPH)\n",
    "print(L_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### ILP implementation\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_directional_segment_frequencies(car_routes_segments):\n",
    "    segment_to_cars = defaultdict(set)\n",
    "\n",
    "    for car_id, routes in car_routes_segments.items():\n",
    "        for route in routes:\n",
    "            for segment in route:\n",
    "                segment_to_cars[segment].add(car_id)\n",
    "\n",
    "    segment_freq = {seg: len(cars) for seg, cars in segment_to_cars.items()}\n",
    "    return segment_freq\n",
    "\n",
    "def compute_congestion_scores(car_routes_segments, segment_freq):\n",
    "    congestion_scores = {}\n",
    "\n",
    "    for car_id, routes in car_routes_segments.items():\n",
    "        for idx, route in enumerate(routes):\n",
    "            score = sum(segment_freq.get(seg, 0) for seg in route)\n",
    "            avg_score = score / max(len(route), 1)\n",
    "            congestion_scores[(car_id, idx)] = avg_score\n",
    "    return congestion_scores\n",
    "\n",
    "\n",
    "def calculate_weights_from_congestion_scores(congestion_scores):\n",
    "    weights = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    all_keys = congestion_scores.keys()\n",
    "    cars = sorted(set(i for i, _ in all_keys))\n",
    "    ks = sorted(set(k for _, k in all_keys))\n",
    "\n",
    "    for i, j in combinations(cars, 2):\n",
    "        for k in ks:\n",
    "            if (i, k) in congestion_scores and (j, k) in congestion_scores:\n",
    "                score_i = max(0, congestion_scores[(i, k)] - 1)\n",
    "                score_j = max(0, congestion_scores[(j, k)] - 1)\n",
    "                avg = (score_i + score_j) / 2\n",
    "                weights[i][j][k] = avg\n",
    "                weights[j][i][k] = avg\n",
    "    return weights\n",
    "\n",
    "\n",
    "from pulp import LpProblem, LpMinimize, LpVariable, lpSum, LpBinary, PULP_CBC_CMD\n",
    "from itertools import combinations\n",
    "\n",
    "def solve_cluster_ilp_with_aux_vars(cluster_car_ids, k, weights):\n",
    "    \"\"\"\n",
    "    ILP for assigning routes to cars with accurate congestion weights.\n",
    "    Uses auxiliary variables to model x[i,r] * x[j,r].\n",
    "    \"\"\"\n",
    "    prob = LpProblem(\"RouteAssignmentWithAux\", LpMinimize)\n",
    "\n",
    "    # 1. Binary decision variables: x[i][r] = 1 if car i chooses route r\n",
    "    x = {(i, r): LpVariable(f\"x_{i}_{r}\", cat=LpBinary)\n",
    "         for i in cluster_car_ids for r in range(k)}\n",
    "\n",
    "    # 2. Constraints: Each car must choose exactly one route\n",
    "    for i in cluster_car_ids:\n",
    "        prob += lpSum(x[i, r] for r in range(k)) == 1\n",
    "\n",
    "    # 3. Auxiliary variables: z[i][j][r] = 1 if both i and j choose route r\n",
    "    z = {}\n",
    "    for i, j in combinations(cluster_car_ids, 2):\n",
    "        for r in range(k):\n",
    "            z[(i, j, r)] = LpVariable(f\"z_{i}_{j}_{r}\", cat=LpBinary)\n",
    "\n",
    "            # Add constraints to model z_ijr = x_ir * x_jr\n",
    "            prob += z[(i, j, r)] <= x[i, r]\n",
    "            prob += z[(i, j, r)] <= x[j, r]\n",
    "            prob += z[(i, j, r)] >= x[i, r] + x[j, r] - 1\n",
    "\n",
    "    # 4. Objective: minimize weighted overlap (accurate!)\n",
    "    terms = []\n",
    "    for (i, j, r), var in z.items():\n",
    "        w = weights.get(i, {}).get(j, {}).get(r, 0)\n",
    "        terms.append(w * var)\n",
    "\n",
    "    prob += lpSum(terms)\n",
    "\n",
    "    # 5. Solve\n",
    "    prob.solve(PULP_CBC_CMD(msg=False))\n",
    "\n",
    "    # 6. Extract solution\n",
    "    result = {}\n",
    "    for i in cluster_car_ids:\n",
    "        for r in range(k):\n",
    "            if x[i, r].varValue == 1:\n",
    "                result[i] = r\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6786c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_freq = compute_directional_segment_frequencies(car_routes_segments)\n",
    "congestion_scores = compute_congestion_scores(car_routes_segments, segment_freq)\n",
    "weights = calculate_weights_from_congestion_scores(congestion_scores)\n",
    "\n",
    "K_ALTERNATIVES = len(next(iter(car_routes_segments.values())))  # assumes same k for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions = []\n",
    "#for cluster in L_:\n",
    "    #car_ids = list(cluster)\n",
    "    #print(car_ids)\n",
    "    #print(K_ALTERNATIVES)\n",
    "    #print(weights)\n",
    "    #result = solve_cluster_ilp_with_aux_vars(car_ids, K_ALTERNATIVES, weights)\n",
    "    #solutions.append(result)\n",
    "    #print(f\"Cluster with {len(car_ids)} cars → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def solve_cluster_greedy(cluster_car_ids, k, weights):\n",
    "    \"\"\"\n",
    "    Greedy route assignment: assign each car a route that minimizes its added overlap\n",
    "    based on already assigned cars using congestion weights.\n",
    "\n",
    "    Args:\n",
    "        cluster_car_ids: list of car IDs in the cluster\n",
    "        k: number of route alternatives per car\n",
    "        weights: dict[i][j][r] where r is route index, and weights are symmetric\n",
    "\n",
    "    Returns:\n",
    "        result: dict of {car_id: selected_route_index}\n",
    "    \"\"\"\n",
    "    assigned = {}  # {car_id: route_idx}\n",
    "\n",
    "    for i in cluster_car_ids:\n",
    "        best_score = float('inf')\n",
    "        best_route = 0\n",
    "\n",
    "        for r in range(k):\n",
    "            score = 0\n",
    "\n",
    "            # Accumulate interaction cost with already assigned cars\n",
    "            for j in assigned:\n",
    "                rj = assigned[j]\n",
    "                # Prefer symmetric access to weights\n",
    "                w_ij = weights.get(i, {}).get(j, {}).get(r, 0)\n",
    "                w_ji = weights.get(j, {}).get(i, {}).get(rj, 0)\n",
    "                score += w_ij + w_ji\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_route = r\n",
    "\n",
    "        assigned[i] = best_route\n",
    "\n",
    "    return assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = []\n",
    "for cluster in L_:\n",
    "    car_ids = list(cluster)\n",
    "    print(car_ids)\n",
    "    #print(K_ALTERNATIVES)\n",
    "    #print(weights)\n",
    "    result = solve_cluster_greedy(car_ids, K_ALTERNATIVES, weights)\n",
    "    solutions.append(result)\n",
    "    print(f\"Cluster with {len(car_ids)} cars → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparision\n",
    "\n",
    "def compute_segment_frequencies_from_all_routes(car_routes_segments):\n",
    "    from collections import defaultdict\n",
    "    freq = defaultdict(int)\n",
    "\n",
    "    for routes in car_routes_segments.values():\n",
    "        for route in routes:\n",
    "            for seg in route:\n",
    "                freq[seg] += 1\n",
    "    return freq\n",
    "\n",
    "segment_freq_before = compute_segment_frequencies_from_all_routes(car_routes_segments)\n",
    "\n",
    "def compute_segment_frequencies_from_assignment(car_routes_segments, assignment):\n",
    "    from collections import defaultdict\n",
    "    freq = defaultdict(int)\n",
    "\n",
    "    for car_id, route_idx in assignment.items():\n",
    "        route = car_routes_segments[car_id][route_idx]\n",
    "        for seg in route:\n",
    "            freq[seg] += 1\n",
    "    return freq\n",
    "\n",
    "# Merge all cluster results\n",
    "final_assignment = {}\n",
    "for cluster_result in solutions:  # from ILP loop\n",
    "    final_assignment.update(cluster_result)\n",
    "\n",
    "segment_freq_after = compute_segment_frequencies_from_assignment(car_routes_segments, final_assignment)\n",
    "\n",
    "def compare_congestion_stats(freq_before, freq_after):\n",
    "    total_before = sum(freq_before.values())\n",
    "    total_after = sum(freq_after.values())\n",
    "\n",
    "    unique_segments_before = len(freq_before)\n",
    "    unique_segments_after = len(freq_after)\n",
    "\n",
    "    max_before = max(freq_before.values()) if freq_before else 0\n",
    "    max_after = max(freq_after.values()) if freq_after else 0\n",
    "\n",
    "    return {\n",
    "        \"Total uses before\": total_before,\n",
    "        \"Total uses after\": total_after,\n",
    "        \"Unique segments before\": unique_segments_before,\n",
    "        \"Unique segments after\": unique_segments_after,\n",
    "        \"Max congestion before\": max_before,\n",
    "        \"Max congestion after\": max_after,\n",
    "        \"Δ Total\": total_before - total_after,\n",
    "        \"Δ Max congestion\": max_before - max_after,\n",
    "    }\n",
    "\n",
    "congestion_stats = compare_congestion_stats(segment_freq_before, segment_freq_after)\n",
    "for k, v in congestion_stats.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import Map, PolyLine, Marker\n",
    "from branca.colormap import linear\n",
    "\n",
    "def visualize_assigned_routes(car_routes, final_assignment, congestion_scores):\n",
    "    if not car_routes or not final_assignment:\n",
    "        print(\"No data to display.\")\n",
    "        return None\n",
    "\n",
    "    # Center map on the first car with a route\n",
    "    for car in car_routes:\n",
    "        if car.get(\"routes\"):\n",
    "            center = car[\"origin\"]\n",
    "            break\n",
    "    else:\n",
    "        print(\"⚠️ No routes found.\")\n",
    "        return None\n",
    "\n",
    "    fmap = folium.Map(location=center, zoom_start=13, tiles='cartodbpositron')\n",
    "\n",
    "    # Normalize only the selected congestion scores\n",
    "    selected_scores = [\n",
    "        congestion_scores.get((car['car_id'], final_assignment[car['car_id']]), 0)\n",
    "        for car in car_routes if car['car_id'] in final_assignment\n",
    "    ]\n",
    "    colormap = linear.YlOrRd_09.scale(min(selected_scores), max(selected_scores))\n",
    "    colormap.caption = \"Selected Route Congestion\"\n",
    "    fmap.add_child(colormap)\n",
    "\n",
    "    for car in car_routes:\n",
    "        car_id = car['car_id']\n",
    "        if car_id not in final_assignment:\n",
    "            continue\n",
    "\n",
    "        routes = car.get('routes', [])\n",
    "        route_idx = final_assignment[car_id]\n",
    "\n",
    "        if route_idx >= len(routes):\n",
    "            continue  # Safety check\n",
    "\n",
    "        route = routes[route_idx]\n",
    "        poly = route['geometry']\n",
    "        dist_m = route.get('distance', 0)\n",
    "        time_sec = route.get('duration', 0)\n",
    "        score = congestion_scores.get((car_id, route_idx), 0)\n",
    "        color = colormap(score)\n",
    "\n",
    "        #Marker(location=car['origin'], popup=f\"Car {car_id} Start\").add_to(fmap)\n",
    "        #Marker(location=car['destination'], popup=f\"Car {car_id} End\").add_to(fmap)\n",
    "\n",
    "        tooltip_text = (\n",
    "            f\"Car {car_id} - Route {route_idx}<br>\"\n",
    "            f\"Distance: {dist_m / 1000:.2f} km<br>\"\n",
    "            f\"Duration: {time_sec // 60:.1f} min<br>\"\n",
    "            f\"Congestion Score: {score:.2f}\"\n",
    "        )\n",
    "\n",
    "        PolyLine(\n",
    "            locations=poly,\n",
    "            color=color,\n",
    "            weight=5,\n",
    "            opacity=0.75,\n",
    "            tooltip=tooltip_text\n",
    "        ).add_to(fmap)\n",
    "\n",
    "    return fmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all cluster assignments into one dict\n",
    "final_assignment = {}\n",
    "for cluster_result in solutions:  # from your ILP loop\n",
    "    final_assignment.update(cluster_result)\n",
    "\n",
    "# Now visualize only selected routes\n",
    "map_ = visualize_assigned_routes(CAR_ROUTES, final_assignment, congestion_scores)\n",
    "map_.save(\"optimized_routes_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae8843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

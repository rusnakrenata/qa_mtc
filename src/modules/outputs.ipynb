{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORT MODULES ----------\n",
    "from get_city_graph import get_city_graph\n",
    "from get_city_data_from_db import get_city_data_from_db\n",
    "from store_city_to_db import store_city_to_db\n",
    "from get_or_create_run_config import get_or_create_run_config\n",
    "from create_iteration import create_iteration\n",
    "from generate_vehicles import generate_vehicles\n",
    "from generate_vehicle_routes import generate_vehicle_routes\n",
    "from generate_congestion import generate_congestion\n",
    "from plot_congestion_heatmap import plot_congestion_heatmap, plot_congestion_heatmap_interactive\n",
    "from filter_routes_for_qubo import filter_routes_for_qubo\n",
    "from get_congestion_weights import get_congestion_weights\n",
    "from normalize_congestion_weights import normalize_congestion_weights\n",
    "from congestion_weights import congestion_weights\n",
    "from qubo_matrix import qubo_matrix\n",
    "\n",
    "# ---------- CONFIGURATION ----------\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import * #City, Node, Edge, RunConfig, Iteration, Vehicle, VehicleRoute, CongestionMap, RoutePoint  # adjust to your actual model imports\n",
    "\n",
    "\n",
    "CITY_NAME = \"Bratislava, Slovakia\"#\"Most pri Bratislave, Slovakia\"\n",
    "DIST_THRESH = 10\n",
    "SPEED_DIFF_THRESH = 2\n",
    "RUN_CONFIG_ID = 3#20      \n",
    "ITERATION_ID = 4#1\n",
    "API_KEY = ''\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "\n",
    "city = session.query(City).filter_by(name=CITY_NAME).first()\n",
    "_, edges = get_city_data_from_db(session, city.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4044c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_config_params(session, run_config_id, city_name):\n",
    "    from sqlalchemy import text\n",
    "\n",
    "    # Step 1: Get city_id\n",
    "    city_id_result = session.execute(text(\"\"\"\n",
    "        SELECT id FROM cities WHERE name = :city_name\n",
    "    \"\"\"), {'city_name': city_name}).fetchone()\n",
    "\n",
    "    if city_id_result is None:\n",
    "        raise ValueError(f\"No city found with name '{city_name}'\")\n",
    "\n",
    "    city_id = city_id_result[0]\n",
    "\n",
    "    sql = text(\"\"\"\n",
    "        SELECT\n",
    "            id,\n",
    "            city_id,\n",
    "            n_cars,\n",
    "            k_alternatives,\n",
    "            min_length,\n",
    "            max_length,\n",
    "            time_step,\n",
    "            time_window,\n",
    "            created_at\n",
    "        FROM run_configs\n",
    "        WHERE id = :run_config_id\n",
    "    \"\"\")\n",
    "\n",
    "    result = session.execute(sql, {'run_config_id': run_config_id, 'city_id': city_id}).fetchone()\n",
    "\n",
    "    if result is None:\n",
    "        raise ValueError(f\"No run_config found with id={run_config_id}\")\n",
    "\n",
    "    # Return as dictionary\n",
    "    keys = ['id', 'city_id', 'n_cars', 'k_alternatives', 'min_length',\n",
    "            'max_length', 'time_step', 'time_window', 'created_at']\n",
    "    return dict(zip(keys, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_run_config_params(session, run_config_id=RUN_CONFIG_ID, city_name = CITY_NAME)\n",
    "print(config['n_cars'], config['k_alternatives'], config['min_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b86928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_routes_df(session, run_config_id, iteration_id):\n",
    "    from sqlalchemy import text\n",
    "    import pandas as pd\n",
    "\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            vehicle_id,\n",
    "            route_id,\n",
    "            point_id,\n",
    "            edge_id,\n",
    "            lat,\n",
    "            lon,\n",
    "            time,\n",
    "            speed,\n",
    "            cardinal\n",
    "        FROM trafficOptimization.route_points\n",
    "        WHERE run_configs_id = :run_config_id\n",
    "          AND iteration_id = :iteration_id\n",
    "        ORDER BY vehicle_id, route_id, point_id\n",
    "    \"\"\")\n",
    "\n",
    "    result = session.execute(query, {\n",
    "        'run_config_id': run_config_id,\n",
    "        'iteration_id': iteration_id\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(result.fetchall(), columns=[\n",
    "        'vehicle_id', 'route_id', 'point_id', 'edge_id',\n",
    "        'lat', 'lon', 'time', 'speed', 'cardinal'\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2695a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_congestion_df(session, run_config_id, iteration_id):\n",
    "    from sqlalchemy import text\n",
    "    import pandas as pd\n",
    "\n",
    "    query = text(\"\"\"\n",
    "        SELECT\n",
    "            edge_id,\n",
    "            vehicle1,\n",
    "            vehicle2,   \n",
    "            vehicle1_route,\n",
    "            vehicle2_route,\n",
    "            congestion_score\n",
    "        FROM trafficOptimization.congestion_map\n",
    "        WHERE run_configs_id = :run_config_id\n",
    "          AND iteration_id = :iteration_id\n",
    "    \"\"\")\n",
    "\n",
    "    result = session.execute(query, {\n",
    "        'run_config_id': run_config_id,\n",
    "        'iteration_id': iteration_id\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(result.fetchall(), columns=['edge_id', 'vehicle1', 'vehicle2', 'vehicle1_route', 'vehicle2_route', 'congestion_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#routes_df = get_routes_df(session, RUN_CONFIG_ID, ITERATION_ID)\n",
    "congestion_df = get_congestion_df(session, RUN_CONFIG_ID, ITERATION_ID)\n",
    "\n",
    "\n",
    "# Step 8: Filter routes for QUBO\n",
    "filtered_vehicles = filter_routes_for_qubo(congestion_df, threshold_percentile=0.9)\n",
    "#print(filtered_vehicles)\n",
    "N_FILTERED = len(filtered_vehicles)\n",
    "print(\"Number of elements:\", N_FILTERED)\n",
    "\n",
    "# Step 9: Compute wights from congestion\n",
    "weights_df = get_congestion_weights(session, RUN_CONFIG_ID, ITERATION_ID)\n",
    "#print(weights_df)\n",
    "weights_df.to_csv(\"files/weights_df.csv\", index=False)\n",
    "\n",
    "#weights_normalized = normalize_congestion_weights(weights_df, N_FILTERED, config['k_alternatives'], filtered_vehicles)\n",
    "#weights_wo_normalization, max_weight = congestion_weights(weights_df, N_FILTERED, config['k_alternatives'], filtered_vehicles)\n",
    "#print(weights_normalized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ef512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: QUBO\n",
    "Q, weights, w_c = qubo_matrix(N_FILTERED, config['k_alternatives'], weights_df, filtered_vehicles, lambda_strategy=\"normalized\", fixed_lambda=1.0)\n",
    "\n",
    "#for (q1, q2), value in Q.items():\n",
    "#    print(f\"Q[{q1}, {q2}] = {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7001e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def qubo_dict_to_dataframe(Q, size):\n",
    "    matrix = np.zeros((size, size))\n",
    "    for (i, j), v in Q.items():\n",
    "        matrix[i][j] = v\n",
    "        if i != j:\n",
    "            matrix[j][i] = v  # ensure symmetry for display\n",
    "    return pd.DataFrame(matrix), matrix\n",
    "\n",
    "# Example usage\n",
    "size = N_FILTERED * config['k_alternatives']\n",
    "Q_df, matrix = qubo_dict_to_dataframe(Q, size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51bdf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_df.to_csv(\"files/qubo_matrix.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b0c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_shortest_routes import compute_shortest_routes\n",
    "\n",
    "# Step : Plot heatmap\n",
    "plot_map = plot_congestion_heatmap_interactive(edges, congestion_df,offset_deg=0.000025)\n",
    "plot_map\n",
    "plot_map.save(\"files/congestion_heatmap.html\")\n",
    "\n",
    "shortes_routes_dur_df = compute_shortest_routes(session, RUN_CONFIG_ID, ITERATION_ID, method=\"duration\")\n",
    "plot_map_dur = plot_congestion_heatmap_interactive(edges, shortes_routes_dur_df,offset_deg=0.000025)\n",
    "plot_map_dur\n",
    "plot_map_dur.save(\"files/shortest_routes_dur_congestion_heatmap.html\")\n",
    "\n",
    "\n",
    "shortes_routes_dis_df = compute_shortest_routes(session, RUN_CONFIG_ID, ITERATION_ID, method=\"distance\")\n",
    "plot_map_dis = plot_congestion_heatmap_interactive(edges, shortes_routes_dis_df,offset_deg=0.000025)\n",
    "plot_map_dis\n",
    "plot_map_dis.save(\"files/shortest_routes_dis_congestion_heatmap.html\")\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21256c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Adjust the path as needed\n",
    "file_path = \"files/qubo_matrix.csv\"\n",
    "\n",
    "# Read only the first N rows/columns for a quick check (e.g., N=100)\n",
    "N = 100  # or set to a smaller/larger value as needed\n",
    "df = pd.read_csv(file_path, nrows=N, usecols=range(N))\n",
    "\n",
    "# Check off-diagonal values\n",
    "negatives = []\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if i != j and df.iloc[i, j] < 0:\n",
    "            negatives.append((i, j, df.iloc[i, j]))\n",
    "\n",
    "print(f\"Found {len(negatives)} negative off-diagonal values in the first {N}x{N} block.\")\n",
    "if negatives:\n",
    "    print(\"Sample negative off-diagonal values (row, col, value):\")\n",
    "    print(negatives[:10])\n",
    "else:\n",
    "    print(\"No negative off-diagonal values found in the first block.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915bf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from dimod import SimulatedAnnealingSampler, BinaryQuadraticModel\n",
    "from dwave.system import EmbeddingComposite, DWaveSampler, LeapHybridSampler\n",
    "from dwave.cloud import Client\n",
    "from models import QAResult\n",
    "import logging\n",
    "from typing import Any, Dict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_api_token() -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the API token securely from environment variable or fallback.\n",
    "    \"\"\"\n",
    "    return os.environ.get('QA_API_TOKEN', '123456456afsdgaeh')\n",
    "\n",
    "\n",
    "def authenticate_with_token(token: str) -> bool:\n",
    "    try:\n",
    "        with Client(token=token) as client:\n",
    "            # Log useful profile info\n",
    "            logger.info(f\"Connected as: {client.profile}\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to authenticate with D-Wave: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def qa_testing(\n",
    "    Q: dict,\n",
    "    run_config_id: int,\n",
    "    iteration_id: int,\n",
    "    session: Any,\n",
    "    comp_type: str = 'hybrid',\n",
    "    num_reads: int = 10\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run QUBO formulation for the car-to-trase assignment using a specified quantum/classical sampler.\n",
    "    Requires API token for authentication (set QA_API_TOKEN env variable or fallback to default).\n",
    "\n",
    "    Args:\n",
    "        Q: QUBO matrix as a dictionary {(q1, q2): value}\n",
    "        run_config_id: Run configuration ID\n",
    "        iteration_id: Iteration number\n",
    "        session: SQLAlchemy session\n",
    "        comp_type: 'test', 'hybrid', or 'qpu'\n",
    "        num_reads: Number of reads for classical or QPU runs\n",
    "\n",
    "    Returns:\n",
    "        dict: Results including assignment validity, assignment, energy, and duration.\n",
    "    \"\"\"\n",
    "    # --- Authentication ---\n",
    "    api_token = get_api_token()\n",
    "    if authenticate_with_token(api_token):\n",
    "        logger.info(\"Authentication successful. QA profile loaded.\")\n",
    "    else:\n",
    "        logger.error(\"Authentication failed. Invalid API token.\")\n",
    "        raise PermissionError(\"Invalid API token for QA profile.\")\n",
    "\n",
    "    # --- QUBO to BQM ---\n",
    "    bqm = BinaryQuadraticModel.from_qubo(Q)\n",
    "\n",
    "    # --- Run sampler ---\n",
    "    start_time = time.perf_counter()\n",
    "    if comp_type == 'sa':\n",
    "        sampler = SimulatedAnnealingSampler()\n",
    "        response = sampler.sample(bqm, num_reads=num_reads, seed=42)\n",
    "    elif comp_type == 'hybrid':\n",
    "        sampler = LeapHybridSampler()\n",
    "        response = sampler.sample(bqm)\n",
    "    elif comp_type == 'qpu':\n",
    "        sampler = EmbeddingComposite(DWaveSampler())\n",
    "        response = sampler.sample(bqm, num_reads=num_reads)\n",
    "    else:\n",
    "        logger.error(f\"Unknown comp_type: {comp_type}\")\n",
    "        raise ValueError(f\"Unknown comp_type: {comp_type}\")\n",
    "    duration_qa = time.perf_counter() - start_time\n",
    "\n",
    "    # --- Process results ---\n",
    "    best_sample, energy = response.first\n",
    "\n",
    "    # Infer n and t from Q size (placeholder logic)\n",
    "    n = len(bqm.variables)\n",
    "    t = 1\n",
    "\n",
    "    # Check validity (placeholder: always True)\n",
    "    assignment_valid = True\n",
    "    assignment = list(best_sample.values())\n",
    "\n",
    "    # --- Save QUBO matrix to file ---\n",
    "    def save_qubo(Q, filepath):\n",
    "        with gzip.open(filepath, 'wt', encoding='utf-8') as f:\n",
    "            json.dump(Q, f)\n",
    "\n",
    "    filename = f\"run_{run_config_id}_iter_{iteration_id}.json.gz\"\n",
    "    qubo_dir = Path(\"qubo_matrices\")\n",
    "    filepath = qubo_dir / filename\n",
    "    qubo_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_qubo(Q, filepath)\n",
    "\n",
    "    # --- Store results in DB ---\n",
    "    result_record = QAResult(\n",
    "        run_configs_id=run_config_id,\n",
    "        iteration_id=iteration_id,\n",
    "        lambda_strategy=None,\n",
    "        lambda_value=None,\n",
    "        comp_type=comp_type,\n",
    "        num_reads=num_reads,\n",
    "        n_vehicles=n,\n",
    "        k_alternatives=t,\n",
    "        weights=None,\n",
    "        vehicle_ids=None,\n",
    "        assignment_valid=int(assignment_valid),\n",
    "        assignment=assignment,\n",
    "        energy=energy,\n",
    "        duration=duration_qa,\n",
    "        qubo_path=str(filepath),\n",
    "        created_at=datetime.datetime.utcnow()\n",
    "    )\n",
    "    session.add(result_record)\n",
    "    session.commit()\n",
    "\n",
    "    logger.info(f\"QA testing complete: assignment_valid={assignment_valid}, energy={energy}, duration={duration_qa:.2f}s\")\n",
    "\n",
    "    return {\n",
    "        'comp_type': comp_type,\n",
    "        'num_reads': num_reads,\n",
    "        'n_vehicles': n,\n",
    "        'k_alternattives': t,\n",
    "        'assignment_valid': assignment_valid,\n",
    "        'assignment': assignment,\n",
    "        'energy': energy,\n",
    "        'qubo_path': str(filepath),\n",
    "        'duration': duration_qa\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c111e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to authenticate with D-Wave: 'Client' object has no attribute 'profile'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lSvr-9ba699944c113ae812bfd126c64ec90efb6d4b74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = get_api_token()\n",
    "print(token)\n",
    "authenticate_with_token(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df20665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get('QA_API_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05373287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
